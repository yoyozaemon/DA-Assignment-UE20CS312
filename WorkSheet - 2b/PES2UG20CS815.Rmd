---
title: 'Worksheet 2b : Multiple Linear Regression'
author: "Vijay J, Dept. of CSE - PES2UG20CS815"
date: "2022-09-14"
output: pdf_document
urlcolor: blue
editor_options:
markdown:
wrap: 72
---

## Multiple Linear Regression
Multiple Linear Regression (MLR) is a statistical technique that uses several explanatory variables to predict the outcome of response variable.The goal of MLR is to model a linear relationship between explanatory(independent) variables and response(dependent) variables.

## Loading the Dataset
```{r}
library(tidyverse)
library(ggplot2)
library(car)
library(corrplot)
library(dplyr)
library(dbplyr)
spotify_df <- read_csv('spotify.csv')
```

## Problem - 1
#Solution
```{r}
#Checking the Missing Dataset
sum(is.na(spotify_df))
```

```{r}
#Normalization
colSums(is.na(spotify_df))
spotify_df <- as.data.frame(scale(spotify_df))
spotify_df
```
#*#As we can see there are no missing values in this dataset so there is no need of normalizing the dataframe.

## Problem - 2
#Solution
```{r}
full_model <- lm(energy ~ . , data=spotify_df)
summary(full_model)
```
#*We have taken energy rating as the dependent variable and the remaining attributes as independent variables, which shows that this is a multiple linear regression model.
#*As we can see, the coefficient of determination R2 is higher (0.844), which implies that this is a better fit.

## Problem - 3
#Solution
```{r}
#correlation
correlation <- cor(spotify_df)
corrplot(correlation, method = 'number')
```

```{r}
#Plot-1
plot(x=spotify_df$loudness, y=spotify_df$energy, xlab ="Loudness", ylab="Energy", main="Loudness vs Energy")
```

```{r}
#Plot-2
plot(x=spotify_df$instrumentalness, y=spotify_df$energy, xlab="Instrumentalness", ylab="Energy", main="Instrumentalness vs Energy")
```

```{r}
#Reduce Model
reduce_model <- lm(energy ~ loudness + instrumentalness, data = spotify_df)
summary(reduce_model)
```


## Problem - 4
#Solution
```{r}
#Partial f-test
anova(reduce_model, full_model)
```
#*Null Hypothesis:Only attributes chosen by me are significant for predicting energy.
#*Alternate hypothesis : All attributes are able to predict energy.

## Problem - 5
#Solution
#AIC - Akaike Information Criterio
```{r}
library(olsrr)
stepwise_model <- lm(energy ~ loudness + acousticness + danceability + valence + instrumentalness + mode + key, data=spotify_df)
summary(stepwise_model)
```
#*We can see that std.error has decreased a lot compared to the best fit model, and there is more precise information on estimated values. And there is no change in the  R^2value.And s0 it explains the greatest amount of variation using the fewest number of attributes.

## Problem - 6
#Solution
```{r}
#Plot all the residual
print("Full Model residual Plot")
plot(full_model$residuals, pch = 16, col = "red")
abline(h = 0, lty = 2)
ols_plot_resid_hist(full_model)
print("Reduced Model residual Plot")
plot(reduce_model$residuals, pch = 16, col = "red")
abline(h = 0, lty = 2)
ols_plot_resid_hist(reduce_model)
print("Step-Wise Model residual Plot")
plot(stepwise_model$residuals, pch = 16, col = "red")
abline(h = 0, lty = 2)
ols_plot_resid_hist(stepwise_model)

```
#*We can see that residuals follow a normal distribution, which meets the MLR assumptions, and that there is no high correlation between independent variables, which also meets the MLR assumptions.

## Problem - 7
#Solution
```{r}
#Multicollinearity and Outliers
ols_vif_tol(full_model)
cooksd <- ols_plot_cooksd_chart(full_model)

#4/n and Remove the Outliers
new_df <- spotify_df[-c(30,35,49,84,114,120,127,144,153,159,171,172,187,191),]
new_full_model <- lm(energy ~ . , data =new_df)
summary(new_full_model)
```
#*From the Cook's distance plot, we can see there are outliers, which is why I created a new model which improves the fit.
